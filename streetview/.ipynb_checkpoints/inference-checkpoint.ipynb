{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ceaba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, classification_report\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, top_k_accuracy_score\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "def calculate_metrics(preds, labels, score):\n",
    "    preds, labels = np.asarray(preds), np.asarray(labels)\n",
    "    score = np.asarray(score)\n",
    "    \n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    b_acc = balanced_accuracy_score(labels, preds)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    kappa = cohen_kappa_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average = 'weighted')  \n",
    "    top2 = top_k_accuracy_score(labels, score, k=2)\n",
    "    top3 = top_k_accuracy_score(labels, score, k=3)\n",
    "    \n",
    "    print (\"\\nAccuracy: \" + str(acc))\n",
    "    print (\"Balanced_Accuracy: \" + str(b_acc))\n",
    "    print (\"Kappa: \" + str(kappa))\n",
    "    print (\"F1: \" + str(f1))\n",
    "    print (\"Top-2: \", str(top2))\n",
    "    print (\"Top-3: \", str(top3))\n",
    "    print (cm)\n",
    "    print(classification_report(labels, preds))\n",
    "    \n",
    "    return b_acc\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "class FocalLoss(nn.CrossEntropyLoss):\n",
    "    ''' Focal loss for classification tasks on imbalanced datasets '''\n",
    "\n",
    "    def __init__(self, gamma, alpha=None, ignore_index=-100, reduction='none'):\n",
    "        super().__init__(weight=alpha, ignore_index=ignore_index, reduction='none')\n",
    "        self.reduction = reduction\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input_, target):\n",
    "        cross_entropy = super().forward(input_, target)\n",
    "        # Temporarily mask out ignore index to '0' for valid gather-indices input.\n",
    "        # This won't contribute final loss as the cross_entropy contribution\n",
    "        # for these would be zero.\n",
    "        target = target * (target != self.ignore_index).long()\n",
    "        input_prob = torch.gather(F.softmax(input_, 1), 1, target.unsqueeze(1))\n",
    "        loss = torch.pow(1 - input_prob, self.gamma) * cross_entropy\n",
    "        return torch.mean(loss) if self.reduction == 'mean' \\\n",
    "               else torch.sum(loss) if self.reduction == 'sum' \\\n",
    "               else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "745288ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- FOLD0\n",
      "    Testing...\n",
      "MAE (ICM=1) 1.08 0.844748483277715\n",
      "MAE (ICM=2) 0.5625 0.7358996503970806\n",
      "MAE (ICM=3) 0.8521560574948666 0.5463247301367518\n",
      "MAE (ICM=4) 0.6666666666666666 0.8312473893025002\n",
      "MAE (ICM=5) 1.3125 0.8305683295190107\n",
      "Loss: 0.9902392926914126, Acc: 0.40463724732398987 MAE: \n",
      "\n",
      "Accuracy: 0.40463724756918473\n",
      "Balanced_Accuracy: 0.3265293696720801\n",
      "Kappa: 0.18018741839442598\n",
      "F1: 0.40432876177558397\n",
      "Top-2:  0.712789827973074\n",
      "Top-3:  0.9102468212415856\n",
      "[[  9  34   2   4   1]\n",
      " [ 70 309  71  78   0]\n",
      " [ 28 164 114 167  14]\n",
      " [  9  18  50 100  15]\n",
      " [  1   7  17  46   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.18      0.11        50\n",
      "           1       0.58      0.59      0.58       528\n",
      "           2       0.45      0.23      0.31       487\n",
      "           3       0.25      0.52      0.34       192\n",
      "           4       0.23      0.11      0.15        80\n",
      "\n",
      "    accuracy                           0.40      1337\n",
      "   macro avg       0.32      0.33      0.30      1337\n",
      "weighted avg       0.45      0.40      0.40      1337\n",
      "\n",
      "--------------- FOLD1\n",
      "    Testing...\n",
      "MAE (ICM=1) 1.06 0.9676776322722357\n",
      "MAE (ICM=2) 0.7073863636363636 0.7909181387718276\n",
      "MAE (ICM=3) 0.8829568788501027 0.5425026463934086\n",
      "MAE (ICM=4) 0.5442708333333334 0.7958999685781115\n",
      "MAE (ICM=5) 1.1625 0.7490619133289318\n",
      "Loss: 1.0786118596489993, Acc: 0.3552730083465576 MAE: \n",
      "\n",
      "Accuracy: 0.35527299925205685\n",
      "Balanced_Accuracy: 0.3617308972683716\n",
      "Kappa: 0.16884954475795533\n",
      "F1: 0.36351616298270406\n",
      "Top-2:  0.675392670157068\n",
      "Top-3:  0.8952879581151832\n",
      "[[ 19  19   3   9   0]\n",
      " [ 98 219  72 137   2]\n",
      " [ 37  91  93 252  14]\n",
      " [  6  11  22 134  19]\n",
      " [  1   2   4  63  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.38      0.18        50\n",
      "           1       0.64      0.41      0.50       528\n",
      "           2       0.48      0.19      0.27       487\n",
      "           3       0.23      0.70      0.34       192\n",
      "           4       0.22      0.12      0.16        80\n",
      "\n",
      "    accuracy                           0.36      1337\n",
      "   macro avg       0.34      0.36      0.29      1337\n",
      "weighted avg       0.48      0.36      0.36      1337\n",
      "\n",
      "--------------- FOLD2\n",
      "    Testing...\n",
      "MAE (ICM=1) 1.12 0.8938307073116998\n",
      "MAE (ICM=2) 0.6685606060606061 0.7583684299994526\n",
      "MAE (ICM=3) 0.7960301163586585 0.5594175216248993\n",
      "MAE (ICM=4) 0.5347222222222222 0.7584083703209238\n",
      "MAE (ICM=5) 1.225 0.7411983540186797\n",
      "Loss: 0.7690267522128684, Acc: 0.4465220868587494 MAE: \n",
      "\n",
      "Accuracy: 0.4465220643231114\n",
      "Balanced_Accuracy: 0.33633786789869957\n",
      "Kappa: 0.20967579597177322\n",
      "F1: 0.44391464057497587\n",
      "Top-2:  0.7352281226626777\n",
      "Top-3:  0.9177262528047868\n",
      "[[  6  28  14   2   0]\n",
      " [ 20 275 174  59   0]\n",
      " [ 13 120 201 149   4]\n",
      " [  2  14  59 111   6]\n",
      " [  1   4  21  50   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.12      0.13        50\n",
      "           1       0.62      0.52      0.57       528\n",
      "           2       0.43      0.41      0.42       487\n",
      "           3       0.30      0.58      0.39       192\n",
      "           4       0.29      0.05      0.09        80\n",
      "\n",
      "    accuracy                           0.45      1337\n",
      "   macro avg       0.36      0.34      0.32      1337\n",
      "weighted avg       0.47      0.45      0.44      1337\n",
      "\n",
      "--------------- FOLD3\n",
      "    Testing...\n",
      "MAE (ICM=1) 1.195 0.8927345630141134\n",
      "MAE (ICM=2) 0.7054924242424242 0.7985593941612696\n",
      "MAE (ICM=3) 0.8044147843942505 0.5296554771388158\n",
      "MAE (ICM=4) 0.46875 0.7173900177030623\n",
      "MAE (ICM=5) 1.18125 0.7103861186003003\n",
      "Loss: 0.833572939889493, Acc: 0.38893043994903564 MAE: \n",
      "\n",
      "Accuracy: 0.3889304412864622\n",
      "Balanced_Accuracy: 0.3222536245410989\n",
      "Kappa: 0.18108286414718078\n",
      "F1: 0.3827132924549248\n",
      "Top-2:  0.6641735228122663\n",
      "Top-3:  0.8900523560209425\n",
      "[[  2  35   3  10   0]\n",
      " [  3 269  86 168   2]\n",
      " [  1 100  93 284   9]\n",
      " [  0   8  23 148  13]\n",
      " [  0   4   4  64   8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.04      0.07        50\n",
      "           1       0.65      0.51      0.57       528\n",
      "           2       0.44      0.19      0.27       487\n",
      "           3       0.22      0.77      0.34       192\n",
      "           4       0.25      0.10      0.14        80\n",
      "\n",
      "    accuracy                           0.39      1337\n",
      "   macro avg       0.38      0.32      0.28      1337\n",
      "weighted avg       0.48      0.39      0.38      1337\n",
      "\n",
      "--------------- FOLD4\n",
      "    Testing...\n",
      "MAE (ICM=1) 1.192 0.8735765564619966\n",
      "MAE (ICM=2) 0.6761363636363636 0.8029530230110192\n",
      "MAE (ICM=3) 0.8193018480492813 0.5104625325951386\n",
      "MAE (ICM=4) 0.478125 0.7313946616168775\n",
      "MAE (ICM=5) 1.185 0.721647420836519\n",
      "Loss: 1.0473737862136434, Acc: 0.41585642099380493 MAE: \n",
      "\n",
      "Accuracy: 0.4158563949139865\n",
      "Balanced_Accuracy: 0.3360448323066393\n",
      "Kappa: 0.19440494807438158\n",
      "F1: 0.39350131239542396\n",
      "Top-2:  0.706058339566193\n",
      "Top-3:  0.9109947643979057\n",
      "[[  6  35   3   6   0]\n",
      " [ 19 341  60 108   0]\n",
      " [  9 163  76 231   8]\n",
      " [  4  23  28 124  13]\n",
      " [  0   8   9  54   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.12      0.14        50\n",
      "           1       0.60      0.65      0.62       528\n",
      "           2       0.43      0.16      0.23       487\n",
      "           3       0.24      0.65      0.35       192\n",
      "           4       0.30      0.11      0.16        80\n",
      "\n",
      "    accuracy                           0.42      1337\n",
      "   macro avg       0.35      0.34      0.30      1337\n",
      "weighted avg       0.45      0.42      0.39      1337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch, pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mean = [0.485, 0.456, 0.406] \n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "    transforms.Resize(384),\n",
    "    transforms.CenterCrop(384),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "modelpath = '/mnt/DADOS_PARIS_1/laranjeira/Dengue-Fachada/models/'\n",
    "with open(f'{modelpath}folds.dict', 'rb') as fp:\n",
    "    folds = pickle.load(fp)\n",
    "    \n",
    "model = models.efficientnet_v2_s(pretrained=True)\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "                            nn.Dropout(p=0.2, inplace=True),\n",
    "                            nn.Linear(in_features=num_ftrs, out_features=5, bias=True))\n",
    "\n",
    "class_weights = torch.FloatTensor([4.7, 1.0, 0.54, 0.5, 1.2]).to(device)\n",
    "criterion = FocalLoss(gamma=2, alpha = class_weights, reduction='mean').to(device)\n",
    "\n",
    "\n",
    "dstpath = '/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_streetview'\n",
    "dataset = datasets.ImageFolder(dstpath, transform=data_transforms)\n",
    "\n",
    "mae = [[],[],[],[],[]]\n",
    "results = {'filename': [], 'lat': [], 'long': [], 'label': [], \n",
    "           'pred0': [], 'pred1': [], 'pred2': [], 'pred3': [], 'pred4': []}\n",
    "for fold, test_ids in enumerate(folds['test']):\n",
    "    print('-'*15, f'FOLD{fold}')\n",
    "    model.load_state_dict(torch.load(f'{modelpath}best_fold0{fold+1}.pt'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print('    Testing...')\n",
    "    losses, errors, correct = [], [], 0.\n",
    "    val_pred, val_score, val_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for it, data in enumerate(dataset):\n",
    "            inps, labs = data\n",
    "            \n",
    "            filename, label = dataset.imgs[it]\n",
    "            if filename not in results['filename']: \n",
    "                results['filename'].append(filename)\n",
    "                results['lat']     .append(float(filename.split('_')[-2]))\n",
    "                results['long']    .append(float(filename.split('_')[-1][:-4]))\n",
    "                results['label']   .append(label)\n",
    "                \n",
    "                for i in range(5): results[f'pred{i}'].append(-1)\n",
    "                \n",
    "            idx = results['filename'].index(filename)\n",
    "\n",
    "            inps = inps[None].to(device)\n",
    "            labs = torch.LongTensor([labs]).to(device)\n",
    "            output = model(inps)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            val_labels += labs.cpu().numpy().tolist()\n",
    "            val_pred += output.max(1)[1].cpu().numpy().tolist()\n",
    "            val_score += output.detach().cpu().numpy().tolist()\n",
    "            correct += torch.sum(preds == labs.data)\n",
    "            errors += torch.abs(preds - labs.data)\n",
    "\n",
    "            results[f'pred{fold}'][idx] = preds[0].item()\n",
    "            \n",
    "            loss = criterion(output, labs)\n",
    "            losses.append(loss.data.item()) \n",
    "    \n",
    "    \n",
    "    for clas in range(5):\n",
    "        idx = [k for k, v in enumerate(val_labels) if v == clas]\n",
    "        mae[clas].extend(np.abs(np.array(val_pred)[idx] - np.array(val_labels)[idx]))\n",
    "        print(f'MAE (ICM={clas+1})', np.mean(mae[clas]), np.std(mae[clas]))\n",
    "    \n",
    "    print(f'Loss: {np.mean(losses)}, Acc: {correct/len(dataset)}', 'MAE: ')\n",
    "    calculate_metrics(val_pred, val_labels, val_score)\n",
    "    \n",
    "    ########## Figures ###############\n",
    "#     plt.style.use('default')\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     cm = confusion_matrix(val_labels, val_pred)\n",
    "#     cm_val = normalize(cm, axis=1, norm='l1')\n",
    "\n",
    "#     disp = ConfusionMatrixDisplay(cm_val)\n",
    "#     disp.plot(cmap='Blues')\n",
    "\n",
    "#     plt.title('Normalized confusion matrix')\n",
    "#     plt.xticks(np.arange(5), np.arange(1,6))\n",
    "#     plt.yticks(np.arange(5), np.arange(1,6))\n",
    "#     plt.ylabel('True ICM')\n",
    "#     plt.ylabel('Predicted ICM')\n",
    "#     plt.savefig(f'cm_fold0{fold+1}.pdf', bbox_inches='tight', format='pdf', dpi=150)\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.style.use('ggplot')\n",
    "#     plt.rcParams.update({'font.size': 14})\n",
    "#     for k in range(5):\n",
    "#         idx = [i for i, v in enumerate(val_labels) if v == k]\n",
    "#         scores = tf.softmax(torch.Tensor(val_score))[idx]\n",
    "\n",
    "#         df = pd.DataFrame(scores.numpy())\n",
    "#         fig, ax = plt.subplots(figsize=(7, 4))\n",
    "#         ax.errorbar(np.arange(5), df.mean(), yerr=df.std(), \n",
    "#                 linestyle='dotted', marker='o', markersize=8)\n",
    "\n",
    "#         plt.title(f'ICMNet activations when ICM={k+1}')\n",
    "#         plt.savefig(f'activations_fold0{fold+1}_ICM0{k+1}.pdf', bbox_inches='tight', format='pdf', dpi=150)\n",
    "#         plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd089aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv('inferences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d4d03b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>label</th>\n",
       "      <th>pred0</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str...</td>\n",
       "      <td>-22.990885</td>\n",
       "      <td>-47.121830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str...</td>\n",
       "      <td>-22.969423</td>\n",
       "      <td>-47.145522</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str...</td>\n",
       "      <td>-22.992843</td>\n",
       "      <td>-47.120805</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str...</td>\n",
       "      <td>-22.993735</td>\n",
       "      <td>-47.119886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>/mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str...</td>\n",
       "      <td>-22.945076</td>\n",
       "      <td>-47.099512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filename        lat       long  \\\n",
       "65  /mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str... -22.990885 -47.121830   \n",
       "66  /mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str... -22.969423 -47.145522   \n",
       "67  /mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str... -22.992843 -47.120805   \n",
       "68  /mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str... -22.993735 -47.119886   \n",
       "69  /mnt/DADOS_PARIS_1/laranjeira/Datasets/ICM_str... -22.945076 -47.099512   \n",
       "\n",
       "    label  pred0  pred1  pred2  pred3  pred4  \n",
       "65      1      1      1      1      1      1  \n",
       "66      1      3      3      2      2      3  \n",
       "67      1      3      2      3      3      3  \n",
       "68      1      1      1      1      3      1  \n",
       "69      1      1      3      2      3      1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[65:70]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
